{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from sklearn.mixture import GaussianMixture as GM\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "from sklearn.metrics import davies_bouldin_score as DBS\n",
    "\n",
    "\n",
    "from matplotlib import style\n",
    "\n",
    "import seaborn as sns\n",
    "###################\n",
    "from sklearn.cluster import AgglomerativeClustering as AggClust\n",
    "#from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test previous code:\n",
    "\n",
    "#obj_daily, storage_profit_daily, wind_curtailment_daily, wind_notcurtailed_daily, storage_op_dict, dict_ess_profile, dict_details, obj_cost_breakdown = storage_included_uc(skip_LMP=True, ess_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def reduce_df_to_one_row(my_df, row_idx):\n",
    "    return my_df.iloc[[row_idx]]\n",
    "\n",
    "def storage_included_uc_24bus(skip_LMP=True,ess_flag=False, folder_main=\"data_original\\\\\", \n",
    "                              day_idx=None, curt_cost=500,\n",
    "                             add_noise=False):\n",
    "    ###\n",
    "    \n",
    "    \"\"\"\n",
    "    Unit commitment for 365 days for the 3-bus test system\n",
    "    \"\"\"\n",
    "    \n",
    "    Demand = 2650 \n",
    "    parent_path = \"E:\\\\second_paper\\\\Code_and_Data\\\\paper2_data_input\\\\\" \n",
    "    non_system_data_path = parent_path + folder_main\n",
    "    \n",
    "    ## IMPORT DATA ##\n",
    "    df_load_profile = pd.read_csv(non_system_data_path + \"Load.csv\") \n",
    "    \n",
    "    if add_noise:\n",
    "        seed = int(np.sqrt(abs(hash('Load'))))\n",
    "        np.random.seed(seed)\n",
    "        noise = (10 * np.random.rand(*df_load_profile.shape) - 5)/50\n",
    "        df_load_profile = df_load_profile + noise\n",
    "        df_load_profile = np.clip(df_load_profile, a_min=0, a_max=1)\n",
    "\n",
    "    \n",
    "    if day_idx is not None:\n",
    "        df_load_profile = reduce_df_to_one_row(df_load_profile, day_idx)\n",
    "    \n",
    "\n",
    "    #should be removed!\n",
    "    #df_wind_profile = pd.read_csv(\"InputData_Wind.csv\")\n",
    "    #df_wind_profile_extra = pd.read_csv(\"InputData_Wind_extra.csv\")\n",
    "    #df_wind_profile_extra_bus1 = pd.read_csv(\"InputData_Wind_extra_bus1.csv\")\n",
    "    \n",
    "    #df_wind_profile_dict={}\n",
    "    #df_wind_profile_dict[1] = df_wind_profile_extra_bus1\n",
    "    #df_wind_profile_dict[2] = df_wind_profile\n",
    "    #df_wind_profile_dict[3] = df_wind_profile\n",
    "    #df_wind_profile_dict[4] = df_wind_profile_extra\n",
    "    \n",
    "    \n",
    "\n",
    "    df = pd.read_excel(parent_path + 'System_Data_24_bus.xlsx', sheet_name=None, engine='openpyxl')\n",
    "\n",
    "    \n",
    "    ## SETTINGS ##\n",
    "    UF=0;\n",
    "    DF=2;\n",
    "    VOLL=1e6;\n",
    "    Curt= curt_cost;  #50 was good for k=10, (also ESS P30E150), also k=2\n",
    "    \n",
    "    #print(\"df['GDATA']['genNo.']: \\n\", df['GDATA']['genNo.']);\n",
    "    \n",
    "    gen_set=list(set(df['GDATA']['genNo.']));\n",
    "    #print('gen_set: ', gen_set);\n",
    "    \n",
    "    bus_set = list(set(df['CapD']['bus']));\n",
    "    #print('bus_set: ', bus_set)\n",
    "    \n",
    "    lin_set = list(set(df['LDATA']['lineNo.']));\n",
    "    #print('lin_set: ', lin_set)\n",
    "    \n",
    "    t_set = list(range(1,df_load_profile.shape[1]));  #why not .shape[]+1\n",
    "    d_set = list(range(1,df_load_profile.shape[0]+1));\n",
    "    stor_set = list(set(df['SDATA']['storNo.']))\n",
    "    \n",
    "    #print('>>>')\n",
    "    #print(\"df['MapG'].to_numpy() \\n\", df['MapG'].to_numpy())\n",
    "    #print('<<<')\n",
    "    \n",
    "    #print('\\n t_set: ', t_set)\n",
    "\n",
    "    GDATA = df['GDATA'].set_index(['genNo.']).to_dict()\n",
    "    LDATA = df['LDATA'].set_index(['lineNo.']).to_dict()\n",
    "    SDATA = df['SDATA'].set_index(['storNo.']).to_dict()\n",
    "    \n",
    "\n",
    "\n",
    "    MapG={}\n",
    "    MapL={}\n",
    "    MapS={}\n",
    "\n",
    "\n",
    "    for b in range(len(bus_set)):\n",
    "        for g in range(len(gen_set)):\n",
    "            MapG[bus_set[b],gen_set[g]] = df['MapG'].to_numpy()[g][b]\n",
    "        for l in range(len(lin_set)):\n",
    "            MapL[bus_set[b],lin_set[l]] = df['MapL'].to_numpy()[l][b]\n",
    "\n",
    "        for s in range(len(stor_set)):\n",
    "            MapS[bus_set[b],stor_set[s]] = df['MapS'].to_numpy()[s][b]\n",
    "\n",
    "\n",
    "    #print('\\n MapG: \\n', MapG)\n",
    "    #print('-------------')\n",
    "    #print('\\n MapL: \\n', MapL)\n",
    "\n",
    "\n",
    "    P_wind={}\n",
    "    P_load={}\n",
    "    for b in range(len(bus_set)):\n",
    "        #print('bus (as index) is: ', b)\n",
    "        \n",
    "        ###if df['CapW']['Wind'].to_numpy()[b]>0:\n",
    "        ###   name_of_RE = df['CapW'].loc[b,'Profile']\n",
    "        ######print('name_of_RE: ', name_of_RE)\n",
    "        \n",
    "        if df['CapW']['Wind'].to_numpy()[b]>0: #else: means there is no wf.. and so...no name_of_RE\n",
    "            name_of_RE = df['CapW'].loc[b,'Profile']\n",
    "            df_wind_profile = pd.read_csv(non_system_data_path + (name_of_RE + \".csv\"))\n",
    "        \n",
    "            if add_noise:\n",
    "                seed = int(np.sqrt(abs(hash(name_of_RE))))\n",
    "                np.random.seed(seed)\n",
    "                noise = (10 * np.random.rand(*df_wind_profile.shape) - 5)/50\n",
    "                df_wind_profile = df_wind_profile + noise\n",
    "                df_wind_profile = np.clip(df_wind_profile, a_min=0, a_max=1)\n",
    "\n",
    "        \n",
    "        for t in range(len(t_set)):\n",
    "            for d in range(len(d_set)):\n",
    "                \n",
    "                #P_wind[bus_set[b],t_set[t],d_set[d]]=df['CapW']['Wind'].to_numpy()[b]*df_wind_profile.to_numpy()[d][t+1]\n",
    "                \n",
    "                if df['CapW']['Wind'].to_numpy()[b]==0:\n",
    "                    P_wind[bus_set[b],t_set[t],d_set[d]] = 0\n",
    "                else:\n",
    "                    df_wind_profile_to_use = df_wind_profile.copy()\n",
    "                    if day_idx is not None:\n",
    "                        df_wind_profile_to_use = reduce_df_to_one_row(df_wind_profile_to_use, day_idx)\n",
    "                    \n",
    "                \n",
    "                    P_wind[bus_set[b],t_set[t],d_set[d]]=df['CapW']['Wind'].to_numpy()[b] * df_wind_profile_to_use.to_numpy()[d][t+1]\n",
    "                \n",
    "                P_load[bus_set[b],t_set[t],d_set[d]]=((0.01 * df['CapD']['Load_Percentage'].to_numpy()[b]) * Demand) * df_load_profile.to_numpy()[d][t+1]\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "    #print('-----')\n",
    "    #print('>>> P_wind: ', P_wind)\n",
    "    #print('-----')\n",
    "\n",
    "\n",
    "\n",
    "    model=pe.ConcreteModel()\n",
    "\n",
    "    #Variables\n",
    "\n",
    "    # >>> p line, voltage angles of buses, and p gen\n",
    "    model.PL = pe.Var(lin_set,t_set,d_set,domain=pe.Reals)\n",
    "    model.theta = pe.Var(bus_set,t_set,d_set,domain=pe.Reals)\n",
    "    model.PG = pe.Var(gen_set,t_set,d_set,domain=pe.NonNegativeReals)\n",
    "\n",
    "    # >>> Loadloss and Curtailment variables\n",
    "    model.PLS = pe.Var(bus_set,t_set,d_set,domain=pe.NonNegativeReals)\n",
    "    model.Pcurt = pe.Var(bus_set,t_set,d_set,domain=pe.NonNegativeReals)\n",
    "\n",
    "    # >>>  on/off, start, shutdown variables of gen\n",
    "    model.w = pe.Var(gen_set,t_set,d_set,domain=pe.Binary)\n",
    "    model.u = pe.Var(gen_set,t_set,d_set,domain=pe.Binary)\n",
    "    model.f = pe.Var(gen_set,t_set,d_set,domain=pe.Binary)\n",
    "\n",
    "    \n",
    "    if ess_flag:\n",
    "        # >>> storage variables\n",
    "        model.pch = pe.Var(stor_set,t_set,d_set,domain=pe.NonNegativeReals)\n",
    "        model.ifch = pe.Var(stor_set,t_set,d_set,domain=pe.Binary)\n",
    "        model.pdch = pe.Var(stor_set,t_set,d_set,domain=pe.NonNegativeReals)\n",
    "        model.ifdch = pe.Var(stor_set,t_set,d_set,domain=pe.Binary)\n",
    "        model.soc = pe.Var(stor_set,t_set,d_set,domain=pe.NonNegativeReals)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ## objective function: minimize operation cost\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def obj_expression(model):\n",
    "        return sum(\n",
    "              sum(\n",
    "                sum((model.PG[g,t,e]*GDATA['Cg'][g]+model.w[g,t,e]*GDATA['Noload'][g]+\n",
    "                     model.u[g,t,e]*GDATA['StartUp'][g]+model.f[g,t,e]*GDATA['ShutDn'][g]) for g in gen_set)+\n",
    "                sum(model.PLS[b,t,e]*VOLL for b in bus_set)+\n",
    "                sum(Curt*model.Pcurt[b,t,e] for b in bus_set)\n",
    "            for t in t_set)\n",
    "                for e in d_set)\n",
    "    \n",
    "    \n",
    "    model.OBJ = pe.Objective(rule=obj_expression, sense=pe.minimize)\n",
    "\n",
    "    #  constraint: Power balance constraint\n",
    "    \n",
    "    if ess_flag:\n",
    "        def Lambda_rule(model,b,t,e):\n",
    "            return (sum(model.PG[g,t,e]*MapG[b,g]\n",
    "                       for g in gen_set)-sum(model.PL[l,t,e]*MapL[b,l]\n",
    "                                             for l in lin_set) -  \n",
    "                                            sum(model.pch[s,t,e]*MapS[b,s]\n",
    "                                             for s in stor_set) +  \n",
    "                                            sum(model.pdch[s,t,e]*MapS[b,s]\n",
    "                                             for s in stor_set) + model.PLS[b,t,e]+(P_wind[b,t,e]-model.Pcurt[b,t,e])==P_load[b,t,e])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        def Lambda_rule(model,b,t,e):\n",
    "            return sum(model.PG[g,t,e]*MapG[b,g]\n",
    "                       for g in gen_set)-sum(model.PL[l,t,e]*MapL[b,l]\n",
    "                                             for l in lin_set) + model.PLS[b,t,e]+(P_wind[b,t,e]-model.Pcurt[b,t,e])==P_load[b,t,e]\n",
    "        \n",
    "    \n",
    "    model.Lambda = pe.Constraint(bus_set, t_set, d_set, rule=Lambda_rule)\n",
    "\n",
    "\n",
    "    # constraint: Line Flow constraints\n",
    "    def Delta_rule(model,l,t,e):          \n",
    "        return model.PL[l,t,e]==100*LDATA['B'][l]*sum(MapL[b,l]*model.theta[b,t,e] for b in bus_set)\n",
    "\n",
    "    def Gamma_Plus_rule(model,l,t,e):          \n",
    "        return model.PL[l,t,e]<=LDATA['Flmax'][l]\n",
    "\n",
    "    def Gamma_Minus_rule(model,l,t,e):          \n",
    "        return model.PL[l,t,e]>=-LDATA['Flmax'][l]\n",
    "\n",
    "    model.Delta = pe.Constraint(lin_set, t_set, d_set, rule=Delta_rule)\n",
    "    model.Gamma_Plus = pe.Constraint(lin_set, t_set, d_set, rule=Gamma_Plus_rule)\n",
    "    model.Gamma_Minus = pe.Constraint(lin_set, t_set, d_set, rule=Gamma_Minus_rule)\n",
    "\n",
    "\n",
    "    if ess_flag:\n",
    "        # constraint: Storage constraints\n",
    "        def Charging_rule(model,s,t,e):\n",
    "            return model.pch[s,t,e] <= model.ifch[s,t,e]*SDATA['Ps'][s]\n",
    "\n",
    "\n",
    "        def Discharging_rule(model,s,t,e):\n",
    "            return model.pdch[s,t,e] <=  model.ifdch[s,t,e]*SDATA['Ps'][s]\n",
    "\n",
    "        def vote_rule(model,s,t,e):\n",
    "            return (model.ifch[s,t,e] + model.ifdch[s,t,e] <= 1)\n",
    "\n",
    "\n",
    "        def SOClimitmin_rule(model,s,t,e):\n",
    "            if t==24:\n",
    "                return (model.soc[s,t,e] ==  SDATA['SOCfin'][s]*SDATA['Es'][s])\n",
    "\n",
    "            else:\n",
    "                return (model.soc[s,t,e]>=SDATA['SOCmin'][s]*SDATA['Es'][s])\n",
    "\n",
    "\n",
    "        def SOClimitmax_rule(model,s,t,e):\n",
    "            if t==24:\n",
    "                return (model.soc[s,t,e] ==  SDATA['SOCfin'][s]*SDATA['Es'][s])\n",
    "\n",
    "            else:\n",
    "                return (model.soc[s,t,e] <= SDATA['SOCmax'][s]*SDATA['Es'][s])\n",
    "\n",
    "\n",
    "\n",
    "        def SOC_rule(model,s,t,e):\n",
    "            if t==1:\n",
    "                return model.soc[s,t,e] == SDATA['SOCinit'][s]*SDATA['Es'][s] + (SDATA['eff'][s]*model.pch[s,t,e] - (1/SDATA['eff'][s])*model.pdch[s,t,e])\n",
    "\n",
    "            else:\n",
    "                return model.soc[s,t,e] == model.soc[s,t-1,e] + (SDATA['eff'][s]*model.pch[s,t,e] - (1/SDATA['eff'][s])*model.pdch[s,t,e])\n",
    "\n",
    "        \n",
    "        model.Charging = pe.Constraint(stor_set, t_set, d_set, rule=Charging_rule)\n",
    "        model.Discharging = pe.Constraint(stor_set, t_set, d_set, rule=Discharging_rule)\n",
    "        model.vote = pe.Constraint(stor_set, t_set, d_set, rule=vote_rule)\n",
    "        model.SOClimitmin = pe.Constraint(stor_set, t_set, d_set, rule=SOClimitmin_rule)\n",
    "        model.SOClimitmax = pe.Constraint(stor_set, t_set, d_set, rule=SOClimitmax_rule)\n",
    "        model.SOC = pe.Constraint(stor_set, t_set, d_set, rule=SOC_rule)\n",
    "\n",
    "\n",
    "    # constraint: Genrators constraints\n",
    "    def Mu_Plus_rule(model,g,t,e):          \n",
    "        return model.PG[g,t,e]<=model.w[g,t,e]*GDATA['Pgmax'][g]\n",
    "\n",
    "    def Mu_Minus_rule(model,g,t,e):          \n",
    "        return model.PG[g,t,e]>=model.w[g,t,e]*GDATA['Pgmin'][g]\n",
    "\n",
    "\n",
    "    ###############\n",
    "    ###############\n",
    "\n",
    "\n",
    "    def Ramp_Up_rule(model,g,t,e):\n",
    "        if t<=23:\n",
    "            return model.PG[g,t+1,e]-model.PG[g,t,e]<=GDATA['Ramp'][g]\n",
    "        else:\n",
    "            return -model.PG[g,t,e]<=GDATA['Ramp'][g]\n",
    "\n",
    "    def Ramp_Dn_rule(model,g,t,e):          \n",
    "        if t<=23:\n",
    "            return model.PG[g,t,e]-model.PG[g,t+1,e]<=GDATA['Ramp'][g]\n",
    "        else:\n",
    "            return -model.PG[g,t,e]<=GDATA['Ramp'][g] ######missing - sign? (should be true always)\n",
    "\n",
    "    #############\n",
    "    #############\n",
    "\n",
    "    def Min_Up_rule(model,g,t,e):\n",
    "        if (t>=UF+1):\n",
    "            if t-GDATA['MinUp'][g]+1>=1:\n",
    "                return sum(model.u[g,k,e] for k in range(t-GDATA['MinUp'][g]+1, t)) <=model.w[g,t,e]\n",
    "            else:\n",
    "                return model.w[g,t,e]>=0;\n",
    "        else:\n",
    "            return model.w[g,t,e]>=0;\n",
    "\n",
    "    def Min_Dn_rule(model,g,t,e):\n",
    "        if (t>=DF+1):\n",
    "            if t-GDATA['MinDn'][g]+1>=1:\n",
    "                return sum(model.f[g,k,e] for k in range(t-GDATA['MinDn'][g]+1, t)) <=1-model.w[g,t,e]\n",
    "            else:\n",
    "                return model.w[g,t,e]>=0;\n",
    "        else:\n",
    "            return model.w[g,t,e]>=0;\n",
    "\n",
    "\n",
    "    #############    \n",
    "    #############\n",
    "\n",
    "    def Coordinate_rule(model,g,t,e):\n",
    "        if t>=2:\n",
    "            return model.w[g,t-1,e]-model.w[g,t,e]+model.u[g,t,e]-model.f[g,t,e]==0\n",
    "        else:\n",
    "            return -model.w[g,t,e]+model.u[g,t,e]-model.f[g,t,e]==0\n",
    "\n",
    "\n",
    "    def Start_Shut_rule(model,g,t,e):\n",
    "        return model.u[g,t,e]+model.f[g,t,e]<=1\n",
    "\n",
    "\n",
    "    model.Mu_Plus = pe.Constraint(gen_set, t_set, d_set, rule=Mu_Plus_rule)\n",
    "    model.Mu_Minus = pe.Constraint(gen_set, t_set, d_set, rule=Mu_Minus_rule)\n",
    "    model.Ramp_Up = pe.Constraint(gen_set, t_set, d_set, rule=Ramp_Up_rule)\n",
    "    model.Ramp_Dn = pe.Constraint(gen_set, t_set, d_set, rule=Ramp_Dn_rule)\n",
    "    model.Min_Up = pe.Constraint(gen_set,t_set, d_set, rule=Min_Up_rule)\n",
    "    model.Min_Dn = pe.Constraint(gen_set, t_set, d_set, rule=Min_Dn_rule)\n",
    "    model.Coordinate = pe.Constraint(gen_set, t_set, d_set,rule=Coordinate_rule)\n",
    "    model.Start_Shut = pe.Constraint(gen_set, t_set, d_set,rule=Start_Shut_rule)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "     # constraint: Load Shedding constraint\n",
    "    def Rho_Plus_rule(model,b,t,e):          \n",
    "        return model.PLS[b,t,e]<=P_load[b,t,e]\n",
    "\n",
    "    model.Rho_Plus = pe.Constraint(bus_set, t_set, d_set, rule=Rho_Plus_rule)\n",
    "\n",
    "     # constraint: Angle constraints\n",
    "    def Eta_Ref_rule(model,b,t,e):          \n",
    "        if b==1:\n",
    "            return model.theta[b,t,e]==0\n",
    "        else:\n",
    "            return model.theta[b,t,e]<=3.14\n",
    "\n",
    "    model.Eta_Ref = pe.Constraint(bus_set, t_set, d_set, rule=Eta_Ref_rule)\n",
    "\n",
    "\n",
    "     # constraint: Wind curtailment constraints\n",
    "    def WindCurlim_rule(model,b,t,e):\n",
    "        return model.Pcurt[b,t,e]<=P_wind[b,t,e]                    \n",
    "\n",
    "    model.WindCurlim = pe.Constraint(bus_set, t_set, d_set, rule=WindCurlim_rule)\n",
    "\n",
    "    # SOLVE ##\n",
    "\n",
    "    #model.dual = pe.Suffix(direction=pe.Suffix.IMPORT)\n",
    "\n",
    "\n",
    "\n",
    "    opt = pe.SolverFactory('cplex')\n",
    "\n",
    "    results = opt.solve(model, tee=False) #tee=True (to show the script as being run)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    #############print(results)\n",
    "    #############print(\"\\n >>> (first round) Objective = \", model.OBJ())\n",
    "\n",
    "\n",
    "    #print(\"\\nValue of Total Wind Curtailment (MWh) = \", sum(sum(sum(model.Pcurt[b,t,e].value for b in bus_set) for t in t_set) for e in d_set))\n",
    "\n",
    "    #print(\"\\nValue of Total Load shedding (MWh) = \", sum(sum(sum(model.PLS[b,t,e].value for b in bus_set) for t in t_set) for e in d_set))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #############################################\n",
    "    #############################################\n",
    "    \n",
    "    w_fixed = {}\n",
    "    u_fixed = {}\n",
    "    f_fixed = {}\n",
    "\n",
    "    for g in range(len(gen_set)):\n",
    "        for t in range(len(t_set)):\n",
    "            for d in range(len(d_set)):\n",
    "                w_fixed[gen_set[g],t_set[t],d_set[d]] = round(model.w[gen_set[g],t_set[t],d_set[d]].value)\n",
    "                u_fixed[gen_set[g],t_set[t],d_set[d]] = round(model.u[gen_set[g],t_set[t],d_set[d]].value)\n",
    "                f_fixed[gen_set[g],t_set[t],d_set[d]] = round(model.f[gen_set[g],t_set[t],d_set[d]].value)\n",
    "\n",
    "\n",
    "    if ess_flag:\n",
    "        ifch_fixed = {}\n",
    "        ifdch_fixed = {}\n",
    "\n",
    "\n",
    "        for s in stor_set:\n",
    "            for t in t_set:\n",
    "                for d in d_set:\n",
    "                    ifch_fixed[s,t,d] = round(model.ifch[s,t,d].value)\n",
    "                    ifdch_fixed[s,t,d] = round(model.ifdch[s,t,d].value)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    storage_profit_daily = -1\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    obj_daily = [sum(\n",
    "                sum((model.PG[g,t,e].value*GDATA['Cg'][g]+w_fixed[g,t,e]*GDATA['Noload'][g]+\n",
    "                     u_fixed[g,t,e]*GDATA['StartUp'][g]+f_fixed[g,t,e]*GDATA['ShutDn'][g]) for g in gen_set)+\n",
    "                sum(model.PLS[b,t,e].value*VOLL for b in bus_set)+\n",
    "                sum(Curt*model.Pcurt[b,t,e].value for b in bus_set)\n",
    "            for t in t_set)\n",
    "                for e in d_set]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #g2_cost_daily = [sum(\n",
    "    #        model.PG[2,t,e].value*GDATA['Cg'][2]+w_fixed[2,t,e]*GDATA['Noload'][2]+\n",
    "    #             u_fixed[2,t,e]*GDATA['StartUp'][2]+f_fixed[2,t,e]*GDATA['ShutDn'][2]\n",
    "    #    for t in t_set)\n",
    "    #        for e in d_set]\n",
    "    \n",
    "    \n",
    "    g_cost_daily_lst = []\n",
    "    for g in gen_set:\n",
    "        cost_of_g = sum([sum(model.PG[g,t,e].value*GDATA['Cg'][g]+w_fixed[g,t,e]*GDATA['Noload'][g]+ u_fixed[g,t,e]*GDATA['StartUp'][g]+f_fixed[g,t,e]*GDATA['ShutDn'][g] for t in t_set) for e in d_set])\n",
    "        g_cost_daily_lst.append(cost_of_g)\n",
    "    \n",
    "    \n",
    "                \n",
    "    wind_curt_cost_daily_per_bus = [0]*len(bus_set)\n",
    "    load_shed_cost_daily_per_bus = [0]*len(bus_set)\n",
    "    for id_b, b in enumerate(bus_set):\n",
    "        wind_curt_cost_daily_per_bus[id_b] = sum(sum(Curt*model.Pcurt[b,t,e].value for t in t_set) for e in d_set)\n",
    "        load_shed_cost_daily_per_bus[id_b] = sum(sum(VOLL*model.PLS[b,t,e].value for t in t_set) for e in d_set)\n",
    "    \n",
    "    \n",
    "    per_bus_wind_and_load_cost = {}\n",
    "    per_bus_wind_and_load_cost['wind'] = wind_curt_cost_daily_per_bus\n",
    "    per_bus_wind_and_load_cost['load'] = load_shed_cost_daily_per_bus\n",
    "    \n",
    "    \n",
    "    \n",
    "    #wc_cost_daily = [sum(Curt*model.Pcurt[3,t,e].value\n",
    "    #for t in t_set)\n",
    "    #    for e in d_set]\n",
    "    \n",
    "    \n",
    "    #obj_cost_breakdown = {}\n",
    "    #obj_cost_breakdown['g1'] = g1_cost_daily\n",
    "    #obj_cost_breakdown['g2'] = g2_cost_daily\n",
    "    #obj_cost_breakdown['w'] = wc_cost_daily\n",
    "\n",
    "    \n",
    "    wind_curtailment_daily = [sum(sum(model.Pcurt[b,t,e].value for b in bus_set) for t in t_set) for e in d_set]\n",
    "    wind_notcurtailed_daily = -1 #[sum(sum(P_wind[b,t,e] - model.Pcurt[b,t,e].value for b in bus_set) for t in t_set) for e in d_set]\n",
    "    \n",
    "    \n",
    "    pwind_curt_detail = np.zeros((len(d_set),len(t_set),len(bus_set))) \n",
    "    pwind_generated_detail = np.zeros((len(d_set),len(t_set),len(bus_set)))\n",
    "    \n",
    "    for idx_d, d in enumerate(d_set):\n",
    "        for idx_b, b in enumerate(bus_set):\n",
    "            for idx_t, t in enumerate(t_set):\n",
    "                pwind_curt_detail[idx_d, idx_t, idx_b] = model.Pcurt[b, t, d].value\n",
    "                pwind_generated_detail[idx_d, idx_t, idx_b] = P_wind[b, t, d]\n",
    "                \n",
    "                \n",
    "    re_info_dict={'generated': pwind_generated_detail, \n",
    "                  'curtailed': pwind_curt_detail,\n",
    "                 'format':{'axis0': 'day',\n",
    "                           'axis1': 'time', \n",
    "                           'axis2': 'bus'}\n",
    "                 }\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    gen_power_dict={}\n",
    "    gen_param_dict={}\n",
    "    for g in gen_set:\n",
    "        gen_power_dict[g]=np.zeros((365,24))\n",
    "        gen_param_dict[g] = {}\n",
    "        \n",
    "        for ind_e, e in enumerate(d_set):\n",
    "            for ind_t, t in enumerate(t_set):\n",
    "                gen_power_dict[g][ind_e,ind_t] =  model.PG[g,t,e].value\n",
    "                \n",
    "                if skip_LMP==True:\n",
    "                    gen_param_dict[g]['u'] = model.u[g,t,e].value\n",
    "                    gen_param_dict[g]['f'] = model.f[g,t,e].value\n",
    "                    gen_param_dict[g]['w'] = model.w[g,t,e].value\n",
    "                \n",
    "                else:\n",
    "                    gen_param_dict[g]['u'] = u_fixed[g,t,e]\n",
    "                    gen_param_dict[g]['f'] = f_fixed[g,t,e]\n",
    "                    gen_param_dict[g]['w'] = w_fixed[g,t,e]\n",
    "\n",
    "    \n",
    "    \n",
    "    PLS_dict={}\n",
    "    for b in bus_set:\n",
    "        PLS_dict[b]=np.zeros((365,24))\n",
    "        for ind_e, e in enumerate(d_set):\n",
    "                for ind_t, t in enumerate(t_set):\n",
    "                    PLS_dict[b][ind_e,ind_t] =  model.PLS[b,t,e].value\n",
    "                    if PLS_dict[b][ind_e,ind_t]>0:\n",
    "                        print(f'there is load shedding at e={e}, bus={b} and time={t}: this_much={PLS_dict[b][ind_e,ind_t]}')\n",
    "                    \n",
    "                    tmp = model.Pcurt[b,t,e].value\n",
    "                    if tmp>0:\n",
    "                        print(f'there is wind curt at e={e}, bus={b} and time={t}: this_much={tmp} < {P_wind[b,t,e]}=produced ')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    dict_details={}\n",
    "    dict_details['gen_power'] = gen_power_dict\n",
    "    dict_details['gen_param'] = gen_param_dict\n",
    "    dict_details['load_shed'] = PLS_dict\n",
    "    \n",
    "\n",
    "    dict_ess_profile={}    \n",
    "    if ess_flag:\n",
    "        storage_ch_daily =  np.zeros((len(d_set),len(t_set),len(stor_set)))\n",
    "        storage_dch_daily =  np.zeros((len(d_set),len(t_set),len(stor_set)))\n",
    "        \n",
    "        for ind_e, e in enumerate(d_set):\n",
    "            for ind_t, t in enumerate(t_set):\n",
    "                for ind_s,s in enumerate(stor_set):\n",
    "                    storage_ch_daily[ind_e,ind_t,ind_s] = model.pch[s,t,e].value\n",
    "                    storage_dch_daily[ind_e,ind_t,ind_s] = model.pdch[s,t,e].value\n",
    "                    \n",
    "        #storage_ch_daily = [sum(sum(model.pch[s,t,e].value for s in stor_set) for t in t_set) for e in d_set]\n",
    "        #storage_dch_daily = [sum(sum(model.pdch[s,t,e].value for s in stor_set) for t in t_set) for e in d_set]\n",
    "        storage_op_dict={}\n",
    "        storage_op_dict['ch'] = storage_ch_daily\n",
    "        storage_op_dict['dch'] = storage_dch_daily\n",
    "        \n",
    "        \n",
    "        #ch_profile = np.zeros((365,24))\n",
    "        #for ind_e, e in enumerate(d_set):\n",
    "        #    for ind_t, t in enumerate(t_set):\n",
    "        #        ch_profile[ind_e,ind_t] =  SDATA['eff'][1]*model.pch[1,t,e].value\n",
    "        \n",
    "        \n",
    "        #dch_profile = np.zeros((365,24))\n",
    "        #for ind_e, e in enumerate(d_set):\n",
    "        #    for ind_t, t in enumerate(t_set):\n",
    "        #        dch_profile[ind_e,ind_t] =  (1/SDATA['eff'][1])*model.pdch[1,t,e].value\n",
    "                \n",
    "                \n",
    "        #ch_and_dch_profile = ch_profile - dch_profile\n",
    "        \n",
    "        \n",
    "        #dict_ess_profile['ch_profile']=ch_profile\n",
    "        #dict_ess_profile['dch_profile']=dch_profile\n",
    "        #dict_ess_profile['ch_and_dch_profile']=ch_and_dch_profile\n",
    "        \n",
    "        \n",
    "        \n",
    "        soc_profile = np.zeros((365,24,len(stor_set)))\n",
    "        \n",
    "        for ind_e, e in enumerate(d_set):\n",
    "            for ind_t, t in enumerate(t_set):\n",
    "                for ind_s,s in enumerate(stor_set):\n",
    "                    soc_profile[ind_e,ind_t,ind_s] =  model.soc[s,t,e].value\n",
    "        \n",
    "        \n",
    "        dict_ess_profile['soc_profile']=soc_profile\n",
    "        #print('shape of soc_profile: ', np.shape(soc_profile))\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        dict_ess_profile['ch_and_dch_profile']=-1\n",
    "        dict_ess_profile['soc_profile'] = -1\n",
    "        \n",
    "        storage_op_dict={}\n",
    "        storage_op_dict['ch']=-1\n",
    "        storage_op_dict['dch']=-1\n",
    "        ch_profile=-1\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    lineflows = np.zeros((len(d_set),len(t_set),len(lin_set)))\n",
    "    lineflows_cap = np.zeros(len(lin_set))\n",
    "    \n",
    "    for ind_e, e in enumerate(d_set):\n",
    "        for ind_t, t in enumerate(t_set):\n",
    "            for ind_lne, lne in enumerate(lin_set):\n",
    "                lineflows_cap[ind_lne] = LDATA['Flmax'][lne]\n",
    "                lineflows[ind_e, ind_t, ind_lne] = model.PL[lne,t,e].value / LDATA['Flmax'][lne]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    lineflows_fraction  = np.zeros((len(d_set),len(lin_set)))\n",
    "    for ind_e, e in enumerate(d_set):\n",
    "        for ind_lne, lne in enumerate(lin_set):\n",
    "            tmp =  sum(abs(model.PL[lne,t,e].value) for t in t_set)/24\n",
    "            lineflows_fraction[ind_e, ind_lne] = (1/LDATA['Flmax'][lne]) * tmp\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #print('storage profit: ', storage_profit)\n",
    "\n",
    "\n",
    "    #print(\"\\nValue of Total Wind Curtailment (MWh) = \", sum(sum(sum(model.Pcurt[b,t,e].value for b in bus_set) for t in t_set) for e in d_set))\n",
    "\n",
    "    #print(\"\\nValue of Total Load shedding (MWh) = \", sum(sum(sum(model.PLS[b,t,e].value for b in bus_set) for t in t_set) for e in d_set))\n",
    "\n",
    "    lines_dict={'lineflows' : lineflows, 'lineflows_cap':lineflows_cap}\n",
    "    \n",
    "    return (obj_daily, \n",
    "            storage_profit_daily, \n",
    "            wind_curtailment_daily, \n",
    "            wind_notcurtailed_daily, \n",
    "            storage_op_dict, \n",
    "            dict_ess_profile, \n",
    "            dict_details, \n",
    "            #obj_cost_breakdown, \n",
    "            g_cost_daily_lst, \n",
    "            per_bus_wind_and_load_cost, \n",
    "            re_info_dict, \n",
    "            lines_dict,\n",
    "            model,\n",
    "            lineflows_fraction\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
